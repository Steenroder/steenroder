{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gudhi import SimplexTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'/Users/anibal/Downloads/champs-scalar-coupling/df.csv' does not exist: b'/Users/anibal/Downloads/champs-scalar-coupling/df.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-940d22711c36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/anibal/Downloads/champs-scalar-coupling/df.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'/Users/anibal/Downloads/champs-scalar-coupling/df.csv' does not exist: b'/Users/anibal/Downloads/champs-scalar-coupling/df.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/anibal/Downloads/champs-scalar-coupling/df.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the interesting molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = SimplexTree()\n",
    "interesting_molecules = {}\n",
    "for i in range(1,len(df)):\n",
    "    if df['molecule_name'][i] == df['molecule_name'][i-1]:\n",
    "        \n",
    "        st.insert([df['atom_index_1'][i-1],\n",
    "                   df['atom_index_0'][i-1]], \n",
    "                   -df['scalar_coupling_constant'][i-1])\n",
    "        \n",
    "    else:\n",
    "        st.expansion(3)\n",
    "        barcode = st.persistence(homology_coeff_field=2)\n",
    "        if len(barcode) > 2 and barcode[0][0]>1:\n",
    "            interesting_molecules[df['molecule_name'][i-1]] = st\n",
    "        \n",
    "        st = SimplexTree()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(interesting_molecules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = SimplexTree()\n",
    "interesting_molecules = {}\n",
    "for i in range(1,len(df)):\n",
    "    if df['molecule_name'][i] == df['molecule_name'][i-1]:\n",
    "        \n",
    "        st.insert([df['atom_index_1'][i-1],\n",
    "                   df['atom_index_0'][i-1]], \n",
    "                  -df['scalar_coupling_constant'][i-1])    \n",
    "    else:\n",
    "        break\n",
    "        \n",
    "st.expansion(3)\n",
    "for index, pair in enumerate(st.get_filtration()):\n",
    "    st.assign_filtration(pair[0], index)\n",
    "    \n",
    "barcode = st.persistence(homology_coeff_field=2)\n",
    "print(st.persistence())\n",
    "\n",
    "filtration = tuple([tuple(pair[0]) for pair in st.get_filtration()])\n",
    "coboundary = get_coboundary(filtration)\n",
    "reduced, triangular = get_reduced_triangular(coboundary)\n",
    "\n",
    "barcode = get_barcode(reduced, filtration)\n",
    "barcode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp = ((1,), (2,), (1, 2), (3,), (1, 3), (2, 3), (4,), (1, 4), (2, 4), (1, 2, 4), (3, 4), (2, 3, 4), (5,), (1, 5), (2, 5), (3, 5), (1, 3, 5), (2, 3, 5), (4, 5), (1, 4, 5), (6,), (1, 6), (2, 6), (1, 2, 6), (3, 6), (1, 3, 6), (4, 6), (3, 4, 6), (5, 6), (2, 5, 6), (4, 5, 6))\n",
    "st = SimplexTree()\n",
    "for idx, spx in enumerate(rp):\n",
    "    st.insert(spx, idx)\n",
    "    \n",
    "barcode1 = [bar for bar in st.persistence(homology_coeff_field=2) if bar[1][1]-bar[1][0]>1 or bar[0]==2]\n",
    "\n",
    "filtration = [tuple(pair[0]) for pair in st.get_filtration()]\n",
    "\n",
    "coboundary = get_coboundary(filtration)\n",
    "reduced, triangular = get_reduced_triangular(coboundary)\n",
    "\n",
    "barcode = get_barcode(reduced, filtration)\n",
    "\n",
    "print(barcode1)\n",
    "barcode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for molecule, st in interesting_molecules.items():\n",
    "    # let us remove the filtration value and have strongly \n",
    "    # coupled pairs appearing first\n",
    "    filtration = tuple([tuple(pair[0]) for pair in st.get_filtration()])\n",
    "    \n",
    "    #print(filtration)\n",
    "    coboundary = get_coboundary(filtration)\n",
    "    reduced, triangular = get_reduced_triangular(coboundary)\n",
    "\n",
    "    barcode = get_barcode(reduced, filtration)\n",
    "    #print(len(barcode) == len(st.persistence()))\n",
    "    coho_reps = get_coho_reps(barcode, reduced, triangular)\n",
    "    dimension_masks = get_dimension_masks(barcode)\n",
    "    #print(dimension_masks)\n",
    "    \n",
    "    curve = steenrod_curve(1,1,barcode, coho_reps,\n",
    "                           len(filtration),reduced, dimension_masks)\n",
    "    \n",
    "    if sum(curve) > 1:\n",
    "        plot = plt.plot(range(len(filtration)), \n",
    "                        curve, \n",
    "                        label=f'{molecule[10:]} {sum(curve)}')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steenrod_curve(k,d,barcode,coho_reps,number_simplices,reduced,dimension_masks):\n",
    "    try:\n",
    "        mask = dimension_masks[d]\n",
    "    except:\n",
    "        return [0]*len(filtration)\n",
    "    st_reps = np.empty((number_simplices, len(coho_reps[:,dimension_masks[d]].T)))\n",
    "    for col, rep in enumerate(coho_reps[:,dimension_masks[d]].T):\n",
    "        st_reps[:, col] = STSQ(k,rep,filtration).reshape(-1,)\n",
    "\n",
    "    births = [triple[0] for triple in barcode if triple[2] == d] + [number_simplices]\n",
    "\n",
    "    st_curve = [0]*births[0]\n",
    "    steenrod_matrix = st_reps\n",
    "    for i, b in enumerate(births[:-1]):\n",
    "        for j in range(b, births[i+1]):\n",
    "            steenrod_matrix[:,:i+1] = reduce_matrix(reduced[:,:j],steenrod_matrix[:,:i+1])\n",
    "            st_curve.append(get_rank(steenrod_matrix[:,:i+1]))\n",
    "            \n",
    "    return st_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_coboundary(filtration):\n",
    "    \"\"\"returns the coboundary matrix with respect to the canonical basis \n",
    "    defined by the filtration\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filtration : tuple \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    self : numpy.ndarray\n",
    "    \"\"\"    \n",
    "    \n",
    "    n = len(filtration)\n",
    "    spx_filtration_idx = {tuple(v): idx for idx, v in enumerate(filtration)}\n",
    "    boundary = np.zeros((n, n), dtype=np.bool)\n",
    "    for idx, spx in enumerate(filtration):\n",
    "        faces_idxs = []\n",
    "        try:\n",
    "            faces_idxs = [spx_filtration_idx[spx[:j]+spx[j+1:]] \n",
    "                          for j in range(len(spx))]\n",
    "        except KeyError:\n",
    "            pass\n",
    "        boundary[faces_idxs,idx] = True\n",
    "    \n",
    "    coboundary = np.flip(boundary, axis=[0,1]).transpose()\n",
    "    \n",
    "    return coboundary\n",
    "\n",
    "def pivot(column):\n",
    "    '''returns the position of the pivot of the given column \n",
    "    or None if the zero column is passed \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    column : numpy.narray - shape  \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    self : numpy.ndarray\n",
    "    '''\n",
    "    try:\n",
    "        return max(column.nonzero()[0])\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "def get_reduced_triangular(matrix):\n",
    "    '''R = MV'''\n",
    "    n = matrix.shape[1]\n",
    "    reduced = np.array(matrix)\n",
    "    triangular = np.eye(n, dtype=np.bool)\n",
    "    for j in range(n):\n",
    "        i = j\n",
    "        while i > 0:\n",
    "            i -= 1\n",
    "            if not np.any(reduced[:,j]):\n",
    "                break\n",
    "            else:\n",
    "                piv_j = pivot(reduced[:,j])\n",
    "                piv_i = pivot(reduced[:,i])\n",
    "                \n",
    "                if piv_i == piv_j:\n",
    "                    reduced[:,j] = np.logical_xor(reduced[:,i], reduced[:,j])\n",
    "                    triangular[:,j] = np.logical_xor(triangular[:,i], triangular[:,j])\n",
    "                    i = j\n",
    "                    \n",
    "    return reduced, triangular\n",
    "\n",
    "def get_barcode(reduced, filtration):\n",
    "    '''barcoded ordered by first coordinate'''\n",
    "    dimensions = [len(spx)-1 for spx in reversed(filtration)]\n",
    "    triples = []\n",
    "    all_indices = []\n",
    "    for j in range(len(filtration)):\n",
    "        if np.any(reduced[:,j]):\n",
    "            i = pivot(reduced[:,j])\n",
    "            triples.append((i,j,dimensions[i]))\n",
    "            all_indices += [i,j]\n",
    "    \n",
    "    for i in [i for i in range(len(filtration)) if i not in all_indices]:    \n",
    "        if not np.any(reduced[:,i]):\n",
    "            triples.append((i,np.inf,dimensions[i]))\n",
    "    \n",
    "    barcode = sorted([bar for bar in triples if bar[1]-bar[0]>1])\n",
    "    \n",
    "    return barcode\n",
    "\n",
    "def get_coho_reps(barcode, reduced, triangular):\n",
    "    coho_reps = []\n",
    "    for pair in barcode:\n",
    "        if pair[1] < np.inf:\n",
    "            coho_reps.append(reduced[:,pair[1]])\n",
    "        if pair[1] == np.inf:\n",
    "            coho_reps.append(triangular[:,pair[0]])\n",
    "    return np.transpose(np.array(coho_reps))\n",
    "\n",
    "def get_dimension_masks(barcode):\n",
    "    dimension_masks = {}    \n",
    "    for idx, triple in enumerate(barcode):\n",
    "        dimension = triple[2]\n",
    "        try:\n",
    "            dimension_masks[dimension] += [idx]\n",
    "        except:\n",
    "            dimension_masks[dimension]  = [idx]\n",
    "            \n",
    "    return dimension_masks\n",
    "\n",
    "def vector_to_cochain(vector, filtration):\n",
    "    cocycle = {filtration[-i-1] for i in vector.nonzero()[0]}\n",
    "    return cocycle\n",
    "\n",
    "def cochain_to_vector(cochain, filtration):\n",
    "    simplex_to_index = lambda spx: len(filtration)-filtration.index(spx)-1\n",
    "    nonzero_indices = [simplex_to_index(spx) for spx in cochain]\n",
    "    vector = np.zeros(shape=(len(filtration),1), dtype=np.bool)\n",
    "    vector[nonzero_indices] = True\n",
    "    return vector\n",
    "\n",
    "def STSQ(k, vector, filtration):\n",
    "    \n",
    "    # from vector to cochain\n",
    "    cocycle = vector_to_cochain(vector, filtration)\n",
    "    \n",
    "    # bulk of the algorithm\n",
    "    answer = set()\n",
    "    for pair in combinations(cocycle, 2):\n",
    "        a, b = set(pair[0]), set(pair[1])\n",
    "        if ( len(a.union(b)) == len(a)+k and \n",
    "        tuple(sorted(a.union(b))) in filtration ):\n",
    "            a_bar, b_bar = a.difference(b), b.difference(a)\n",
    "            index = dict()\n",
    "            for v in a_bar.union(b_bar):\n",
    "                pos = sorted(a.union(b)).index(v)\n",
    "                pos_bar = sorted(a_bar.union(b_bar)).index(v)\n",
    "                index[v] = (pos + pos_bar)%2\n",
    "            index_a = {index[v] for v in a_bar}\n",
    "            index_b = {index[w] for w in b_bar}\n",
    "            if (index_a == {0} and index_b == {1} \n",
    "            or  index_a == {1} and index_b == {0}):\n",
    "                u = sorted(a.union(b))\n",
    "                answer ^= {tuple(u)}\n",
    "    \n",
    "    # cochain to vector\n",
    "    st_rep = cochain_to_vector(answer, filtration)\n",
    "    \n",
    "    return st_rep\n",
    "\n",
    "def get_pivots(matrix):\n",
    "    n = matrix.shape[1]\n",
    "    pivots = []\n",
    "    for i in range(n):\n",
    "        pivots.append(pivot(matrix[:,i]))\n",
    "    return pivots\n",
    "\n",
    "def reduce_vector(reduced, vector):\n",
    "    num_col = reduced.shape[1]\n",
    "    i = -1\n",
    "    while i >= -num_col:\n",
    "        if not np.any(vector):\n",
    "            break\n",
    "        else:\n",
    "            piv_v = pivot(vector)\n",
    "            piv_i = pivot(reduced[:,i])\n",
    "\n",
    "            if piv_i == piv_v:\n",
    "                vector[:,0] = np.logical_xor(reduced[:,i], vector[:,0])\n",
    "                i = -1\n",
    "            i -= 1\n",
    "    return vector\n",
    "\n",
    "def reduce_matrix(reduced, matrix):\n",
    "    num_vector = matrix.shape[1]\n",
    "\n",
    "    for i in range(num_vector):\n",
    "        reduced_vector = reduce_vector(reduced, matrix[:, i:i+1])\n",
    "        reduced = np.concatenate([reduced, reduced_vector], axis=1)\n",
    "    return reduced[:, -num_vector:]\n",
    "\n",
    "def get_rank(matrix):\n",
    "    rank = sum(np.apply_along_axis(np.any, 0, matrix).astype(np.int8))\n",
    "    return rank\n",
    "\n",
    "def steenrod_curve(k,d,barcode,coho_reps,number_simplices,reduced,dimension_masks):\n",
    "    st_reps = np.empty((number_simplices, len(coho_reps[:,dimension_masks[d]].T)))\n",
    "    for col, rep in enumerate(coho_reps[:,dimension_masks[d]].T):\n",
    "        st_reps[:, col] = STSQ(k,rep,filtration).reshape(-1,)\n",
    "\n",
    "    births = [triple[0] for triple in barcode if triple[2] == d] + [number_simplices]\n",
    "\n",
    "    st_curve = [0]*births[0]\n",
    "    steenrod_matrix = st_reps\n",
    "    for i, b in enumerate(births[:-1]):\n",
    "        for j in range(b, births[i+1]):\n",
    "            steenrod_matrix[:,:i+1] = reduce_matrix(reduced[:,:j],steenrod_matrix[:,:i+1])\n",
    "            st_curve.append(get_rank(steenrod_matrix[:,:i+1]))\n",
    "            \n",
    "    return st_curve"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
